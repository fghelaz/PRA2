---
title: "PRACTICA2"
author: "FJGL_JMAS"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    theme: cerulean
    toc: yes
    toc_float: true
    toc_depth: 3
    number_sections: yes
    code_folding: hide
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```


# Descripción del dataset. ¿Por qué es importante y qué pregunta/problema pretende responder?

El conjunto de datos que hemos escogido para hacer el estudio es el siguiente: **DATOS DE ECOCARDIAGRAFÍA DE ESTRÉS.** El conjunto de datos stressEcho está disponible en la página web del Departamento de Bioestadística de la Universidad de Vanderbilt. En concreto, se han obtenido de la página web: **https://biostat.app.vumc.org/wiki/Main/DataSets.** 

Hemos escogido este tema porque nos atrae mucho todo lo relacionado con los ecocardiogramas y queremos estudiar la variable **ecg** en función del resto de variables para poder extraer conclusiones, como se verá durante este trabajo.

El **ecocardiograma de estrés** es una prueba utilizada frecuentemente en cardiología que proporciona información en tiempo real acerca del comportamiento tanto del ventrículo izquierdo como de las válvulas en situación de estrés y permite compararlo con el estudio basal en reposo.

Existen diferentes formas de provocar el estrés. La elección de la técnica la sienta el médico que solicita la prueba. La forma más fisiológica es la realización de un ecocardiograma durante el esfuerzo físico que puede realizarse en una cinta rodante similar a la que se utiliza en los gimnasios o en una bicicleta estática. Cuando el paciente no puede realizar ningún tipo de esfuerzo por presentar una limitación física o por su edad se prefiere el ecocardiograma de estrés farmacológico, bien con dobutamina o bien con un vasodilatador (adenosina o dipiridamol).

```{r}

# Antes de empezar cargamos las librerías necesarias:

library(readr)
library(skimr)
library(tidyverse)
library(dplyr)
library(knitr)
library(kableExtra)
library(ggplot2)
library(corrplot)
library(psych)
library(gridExtra)

```


# Integración y selección.

Ahora procedemos a cargar el dataset seleccionado llamado **stressEcho**:

```{r}

# Cargamos el dataset:

stressEcho <- read_csv("C:/Users/Usuario/Dropbox/MASTER UOC/DATA SCIENCE/SEMESTRE 1/TIPOLOGIA DATOS/4_PRACTICA 2/PRACTICA 2/dataset/stressEcho.csv")

```


Una vez cargado el dataset procedemos a ver su dimensión, estructura y tipo de las variables:

```{r}

dim(stressEcho)

str(stressEcho)

```


Podemos ver que tenemos un dataset con 32 variables y 558 observaciones por cada una de ellas. A continuación realizamos una explicación de cada una de estas variables:

    Variables númericas:

      - bhr: frecuencia cardíaca basal.
      - basebp: presión arterial basal.
      - basedp: producto doble basal (= bhr x basebp).
      - pkhr: frecuencia cardíaca máxima.
      - sbp: presión arterial sistólica. 
      - dp: producto doble (= pkhr x sbp). 
      - dose: dosis de dobutamina administrada. 
      - maxhr: frecuencia cardíaca máxima. 
      - pctMphr: % de frecuencia cardíaca máxima predicha alcanzada.
      - mbp: presión arterial máxima. 
      - dpmaxdo: doble producto en dosis máxima de dobutamina.
      - dobdose: dosis de dobutamina a la que se produjo el producto doble máximo. 
      - age: edad el paciente. 
      - baseEF: fracción de eyección cardíaca basal (una medida de la eficiencia de bombeo del corazón). 
      - dobEF: fracción de eyección de dobutamina. 
      
    Variables categóricas dicotómicas:
    
      - gender: género ("male" o "female").
      - chestpain: dolor torácico experimentado (0 = sí). 
      - restwma: anomalía del movimiento de la pared en reposo (0 = sí). 
      - posSE: ecocardiograma de estrés positivo (0 = sí). 
      - newMI: nuevo infarto de miocardio o ataque cardíaco (0 = sí).
      - newPTCA: angioplastia reciente (0 = sí). 
      - newCABG: cirugía de derivación reciente (0 = sí).
      - death: murió (0 = sí). 
      - hxofHT: historial de hipertensión (0 = sí). 
      - hxofDM: historial de diabetes (0 = sí). 
      - hxofMI: historial de ataque al corazón (0 = sí). 
      - hxofPTCA: historia de angioplastia (0 = sí). 
      - hxofCABG: historial de cirugía de bypass (0 = sí). 
      - any.event: death, newMI, newPTCA o newCABG (0 = sí). 
      
    Variables categóricas politómicas:
    
      - hxofCig: historial de fumar ("non-smoker", "moderate" o "heavy").    
      - ecg: diagnóstico basal de ecocardiograma ("normal", "equivocal" o "MI").
      
Después de este resumen de las variables podemos ver que algunas de las variables son dicotómicas y politómicas, es decir, algunas están codificadas como texto en la base de datos pero solo cogen 2 o 3 valores diferentes, y, otras aunque están codificadas como numéricas también cogen unicamente dos valores 0 o 1. Estas variables son las siguientes:

    Variables dicotómicas codificadas como texto:
    
      - gender.
      
    Variables dicotómicas codificadas como numéricas:
    
      - chestpain, restwma, posSE, newMI, newPTCA, newCABG, death, hxofHT, hxofDM, hxofMI, hxofPTCA, hxofCABG, any.event.
      
    Variables politómicas:
    
      - hxofCig, ecg.


A continuación utilizamos la función **skim()** para obtener un resumen de las principales estadísticas descriptivas del conjunto de datos. Esta función permite visualizar rápidamente la distribución de los datos, la presencia de valores ausentes, el tipo de datos y la cantidad de valores únicos en cada variable:

```{r}

skimr::skim(stressEcho)

```


## Variables dicotómicas codificadas como texto:

A continuación nos vamos a centrar en estudiar las **variables dicotómicas** codificadas como texto:

```{r}

# Convertir variable numérica en variable categórica:
stressEcho$gender <- as.factor(stressEcho$gender)

# Crear tabla de frecuencias con porcentajes:
gender_table <- table(stressEcho$gender)
gender_table_percent <- prop.table(gender_table) * 100

# Combinar resultados en un data frame:
gender_table_df <- data.frame(gender = names(gender_table), count = as.vector(gender_table), percent = as.vector(gender_table_percent))

# Crear tabla con kable():
library(knitr)
kable(gender_table_df, col.names = c("Gender", "Count", "Percent"), linesep = "solid", format = "markdown")


# Crear gráfico de barras:
ggplot(stressEcho, aes(x = gender, fill = gender)) +
  geom_bar() +
  labs(x = "gender", y = "Count", fill = "gender") +
  ggtitle("Frequency Distribution of gender")

```


## Variables dicotómicas codificadas como numéricas:

A continuación nos vamos a centrar en estudiar las **variables dicotómicas** codificadas como numéricas:  

```{r}

# Definir lista de variables:
var_list <- c("chestpain", "restwma", "posSE", "newMI", "newPTCA", "newCABG", "death", "hxofHT", "hxofDM", "hxofMI", "hxofPTCA", "hxofCABG", "any.event")

# Crear un bucle for para aplicar el código a cada variable:
for (variable in var_list) {
  # Convertir variable numérica en variable categórica:
  stressEcho[[variable]] <- as.factor(stressEcho[[variable]])
  
  # Crear tabla de frecuencias con porcentajes:
  var_table <- table(stressEcho[[variable]])
  var_table_percent <- prop.table(var_table) * 100
  
  # Combinar resultados en un data frame:
  var_table_df <- data.frame(variable = names(var_table), count = as.vector(var_table), percent = as.vector(var_table_percent))
  
  # Imprimir la tabla con kable():
  print(kable(var_table_df, col.names = c(variable, "Count", "Percent"), linesep = "solid", format = "markdown"))
  
  # Crear gráfico de barras y mostrarlo con print():
  print(ggplot(var_table_df, aes(x = variable, y = count, fill = variable)) + 
        geom_bar(stat = 'identity') + 
        labs(title = paste("Frequency Distribution of", variable), x = variable, y = "Count"))
}

```


## Variables politómicas codificadas como texto:

A continuación nos vamos a centrar en estudiar las **variables politómicas** codificadas como texto: 

```{r}

# Definir lista de variables:
var_list <- c("hxofCig", "ecg")

# Crear un bucle for para aplicar el código a cada variable:
for (variable in var_list) {
  # Convertir variable numérica en variable categórica:
  stressEcho[[variable]] <- as.factor(stressEcho[[variable]])
  
  # Crear tabla de frecuencias con porcentajes:
  var_table <- table(stressEcho[[variable]])
  var_table_percent <- prop.table(var_table) * 100
  
  # Combinar resultados en un data frame:
  var_table_df <- data.frame(variable = names(var_table), count = as.vector(var_table), percent = as.vector(var_table_percent))
  
  # Imprimir la tabla con kable():
  print(kable(var_table_df, col.names = c(variable, "Count", "Percent"), linesep = "solid", format = "markdown"))
  
  # Crear gráfico de barras y mostrarlo con print():
  print(ggplot(var_table_df, aes(x = variable, y = count, fill = variable)) + 
        geom_bar(stat = 'identity') + 
        labs(title = paste("Frequency Distribution of", variable), x = variable, y = "Count"))
}

```


## Variables numéricas:

A continuación nos vamos a centrar en estudiar las **variables numéricas**. En primer lugar miraremos su estructura y buscaremos los estadísticos más importantes:

```{r}

# Crea un subconjunto de datos que excluya las variables dicotómicas
datos_no_dicotomicas <- subset(stressEcho, select = -c(1, 15, 18:32))

# Realiza el análisis en el subconjunto de datos sin las variables dicotómicas
summary(datos_no_dicotomicas)

str(datos_no_dicotomicas)

class(datos_no_dicotomicas)

sapply(datos_no_dicotomicas, is.numeric)

```


Para hacernos una idea visual del comportamiento de estas variables numéricas haremos el **histograma de densidad** para cada una de ellas:

```{r}

# Obtén los nombres de las columnas numéricas
columnas_numericas <- names(datos_no_dicotomicas)[sapply(datos_no_dicotomicas, is.numeric)]

# Crea un histograma para cada columna numérica
for (columna in columnas_numericas) {
  # Extrae los datos de la columna actual
  datos_columna <- datos_no_dicotomicas[[columna]]
  
  # Crea un histograma usando ggplot2
  p <- ggplot(data = datos_no_dicotomicas, aes_string(x = columna)) +
       geom_histogram(aes(y = ..density..), binwidth = 1, fill = "blue", color = "blue") +
       geom_density(alpha = 0.2, fill = "red", size = 2, colour = "red") +
       labs(title = paste("Histograma con densidad de", columna),
            x = columna,
            y = "Densidad")
  
  # Muestra el histograma
  print(p)
}

```


Para hacernos una idea visual de la distribución de estas variables numéricas haremos un **boxplot-violín** para cada una de ellas:

```{r}

# Obtén los nombres de las columnas numéricas
columnas_numericas <- names(datos_no_dicotomicas)[sapply(datos_no_dicotomicas, is.numeric)]

# Crea un violin plot para cada columna numérica
for (columna in columnas_numericas) {
  # Crea un violin plot usando ggplot2
  p <- ggplot(data = datos_no_dicotomicas, aes_string(x = "1", y = columna)) +
       geom_violin(aes(fill = "blue"), alpha = 0.5) +
       geom_boxplot(width = 0.1, color = "red") +
       labs(title = paste("Violin Plot de", columna),
            y = columna,
            x = "")
  
  # Muestra el violin plot
  print(p)
}

```


Por último vamos a ver la **matriz de correlación** entre estas variables numéricas:

```{r}

# Calcula la matriz de correlación
matriz_cor <- cor(datos_no_dicotomicas)

# Muestra la matriz de correlación en una tabla elegante
kable(matriz_cor, format = "html", caption = "Matriz de correlación")

```


Al ser esta tabla difícil de interpretar vamos a crear el **gráfico de correlación** y también vamos a agrupar las variables con un **coeficiente de correlación igual o superior a 0.5** sin valores duplicados:

```{r}

# Crea el gráfico de correlación
corrplot(matriz_cor, method = "circle")

# Encuentra los valores mayores a 0.5 en la matriz de correlación
indices_mayores <- which(matriz_cor > 0.5 & matriz_cor < 1, arr.ind = TRUE)
valores_mayores <- matriz_cor[indices_mayores]

# Obtiene los nombres de las variables correspondientes a los índices
nombres_filas <- rownames(matriz_cor)[indices_mayores[,1]]
nombres_columnas <- colnames(matriz_cor)[indices_mayores[,2]]

# Crea una tabla con los valores mayores a 0.5 y los nombres de las variables correspondientes
tabla_mayores <- data.frame(Variable1 = nombres_filas, Variable2 = nombres_columnas, Correlacion = valores_mayores)

# Elimina las filas duplicadas de la tabla, teniendo en cuenta el orden de las variables
tabla_mayores_sin_duplicados <- tabla_mayores[!duplicated(paste(pmin(tabla_mayores$Variable1, tabla_mayores$Variable2), pmax(tabla_mayores$Variable1, tabla_mayores$Variable2))),]

# Crea la tabla de correlaciones mayores a 0.5 sin duplicados con kableExtra
tabla_cor_mayores <- tabla_mayores_sin_duplicados %>%
  mutate(Correlacion = round(Correlacion, 2)) %>%
  kable(format = "html", caption = "Correlaciones mayores a 0.5 sin duplicados") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Muestra la tabla de correlaciones mayores a 0.5 sin duplicados
tabla_cor_mayores

# Obtiene los nombres de las variables con correlaciones mayores a 0.5 sin duplicados
variables_mayores <- unique(c(tabla_mayores_sin_duplicados$Variable1, tabla_mayores_sin_duplicados$Variable2))

# Muestra el listado de las variables con correlaciones mayores a 0.5 sin duplicados
cat(sprintf("Las variables con correlaciones mayores a 0.5 sin duplicados son: %s", paste(variables_mayores, collapse = ", ")))

```


**Hasta aquí hemos realizado un análisis descriptivo completo de todas las variables de nuestro conjunto de datos para hacernos una idea general de como es y de esta forma poder proseguir con el estudio de éste.**


# Limpieza de los datos.

## ¿Los datos contienen ceros o elementos vacíos?.

Para comprobar valores ausentes en todo el conjunto de datos stressEcho, excluyendo los valores 0 en variables dicotómicas numéricas, primero identificaremos cuáles son las columnas con variables dicotómicas. Luego, verificaremos la presencia de valores ausentes en las columnas no dicotómicas y, para las dicotómicas, solo consideraremos NA como valor ausente. Como la **variable 1 corresponde al id del paciente** la eliminaremos de nuestro conjunto de datos:

```{r}

# Eliminar la primera columna
stressEcho <- stressEcho[, -1]

# Función para verificar si una columna es dicotómica
es_dicotomica <- function(columna) {
  es_factor <- is.factor(columna)
  es_logica <- is.logical(columna)
  valores_unicos <- unique(columna)
  tiene_dos_valores <- length(valores_unicos) == 2
  !es_factor & es_logica & tiene_dos_valores
}

# Identificar columnas dicotómicas
columnas_dicotomicas <- sapply(stressEcho, es_dicotomica)

# Seleccionar las columnas no dicotómicas
columnas_no_dicotomicas <- stressEcho[, !columnas_dicotomicas]

# Calcular número de NA por columna
num_na <- sapply(columnas_no_dicotomicas, function(columna) sum(is.na(columna)))

# Crear un data frame con los resultados
resultados <- data.frame(
  Columna = names(num_na),
  Num_NAs = num_na
)

# Eliminar la primera variable
resultados <- resultados[-1, ]

# Ajustar el ancho de las columnas
col_widths <- c(0.5, 0.3)

# Mostrar la tabla
kable(resultados, col.names = c("Columna", "Número de NAs"),
      align = "l", col_widths = col_widths, space = "m")


```


Realizado esto, podemos afirmar que **no existen valores ausentes.**


## Identifica y gestiona los valores extremos.

Para identificar y gestionar los **valores extremos** en un conjunto de datos, una técnica común es utilizar el **método de los cuartiles**, también conocido como el método IQR (rango intercuartil). Esto implica identificar valores que son significativamente más bajos que el primer cuartil o significativamente más altos que el tercer cuartil.

```{r}

# Función para identificar outliers usando el método IQR y calcular el rango de los valores no extremos
identify_outliers_and_range <- function(x) {
  if (is.numeric(x)) {
    # Calcular cuartiles y rango intercuartil
    Q1 <- quantile(x, 0.25, na.rm = TRUE)
    Q3 <- quantile(x, 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    
    # Identificar valores extremos
    outliers <- x < Q1 - 1.5 * IQR | x > Q3 + 1.5 * IQR
    
    # Calcular rango de los valores no extremos
    non_outliers <- x[!outliers]
    range_non_outliers <- range(non_outliers, na.rm = TRUE)
    
    # Devolver los valores extremos y rango de valores no extremos
    return(list(outliers = x[outliers], range = range_non_outliers))
  } else {
    # Devolver NA para columnas no numéricas
    return(list(outliers = NA, range = NA))
  }
}

# Aplicar la función a cada columna del data frame
outliers_and_range_list <- lapply(stressEcho, identify_outliers_and_range)

# Crear un data frame para los resultados
outliers_and_range_df <- data.frame(
  Variable = character(),
  Outliers = character(),
  Count_of_Outliers = integer(),
  Range_of_Non_Outliers = character(),
  stringsAsFactors = FALSE
)

# Poblar el data frame con los valores extremos, conteo de valores extremos y rango de valores no extremos por variable
for (i in 1:length(outliers_and_range_list)) {
  if (length(outliers_and_range_list[[i]]$outliers) > 0 && !is.na(outliers_and_range_list[[i]]$outliers[1])) {
    outliers_and_range_df <- rbind(outliers_and_range_df, data.frame(
      Variable = names(outliers_and_range_list)[i],
      Outliers = paste(outliers_and_range_list[[i]]$outliers, collapse = ", "),
      Count_of_Outliers = length(outliers_and_range_list[[i]]$outliers),
      Range_of_Non_Outliers = paste(outliers_and_range_list[[i]]$range, collapse = " - "),
      stringsAsFactors = FALSE
    ))
  }
}

# Ajustar el ancho de las columnas
col_widths <- c(0.25, 0.3, 0.2, 0.35)

# Mostrar la tabla
kable(outliers_and_range_df, col.names = c("Variable", "Valores Extremos", "Número de Valores Extremos", "Rango de Valores No Extremos"), 
      align = "l", col_widths = col_widths, space = "m")

```


Hemos podido observar que casi todas las variables presentan valores atípicos. En este sentido, optaremos por eliminar todas estas observaciones extremas (excepto las de la **variable age**) ya que nuestro conjunto de datos es muy grande. Esto lo vamos a realizar con la certeza de que no van a influir en los resultados finales, pues consideramos que hay información de sobra.

Procedemos a **eliminar los valores extremos**:

```{r}

# Función para identificar outliers usando el método IQR y reemplazarlos por NA
remove_outliers <- function(x) {
  if (is.numeric(x)) {
    # Calcular cuartiles y rango intercuartil
    Q1 <- quantile(x, 0.25, na.rm = TRUE)
    Q3 <- quantile(x, 0.75, na.rm = TRUE)
    IQR <- Q3 - Q1
    
    # Identificar valores extremos y reemplazarlos por NA
    x[x < Q1 - 1.5 * IQR | x > Q3 + 1.5 * IQR] <- NA
    
    # Devolver el vector con valores extremos reemplazados por NA
    return(x)
  } else {
    # Devolver el vector sin cambios para columnas no numéricas
    return(x)
  }
}

# Aplicar la función a cada columna del data frame
stressEcho_no_outliers <- data.frame(lapply(stressEcho, remove_outliers))

# Identificar las filas que no contienen valores NA
complete_cases <- complete.cases(stressEcho_no_outliers)

# Comparar el número de filas en el conjunto de datos original y sin valores extremos
n_rows_original <- nrow(stressEcho)
n_rows_no_outliers <- sum(complete_cases)
n_rows_eliminated <- n_rows_original - n_rows_no_outliers

# Imprimir el número de filas eliminadas
cat("Se han eliminado", n_rows_eliminated, "filas del conjunto de datos original.\n")

```

Ahora volvemos a realizar la distribución de las variables mediante un **boxplot-violín** después de eliminar los valores extremos y podemos visualizar un cambio muy sustancial en casi todas ellas, menos en las variables **dose y dobdose**:

```{r}

# Obtén los nombres de las columnas numéricas
columnas_numericas <- names(stressEcho_no_outliers)[sapply(stressEcho_no_outliers, is.numeric)]

# Crea un violin plot para cada columna numérica
for (columna in columnas_numericas) {
  # Crea un violin plot usando ggplot2
  p <- ggplot(data = stressEcho_no_outliers, aes(x = 1, y = get(columna))) +
       geom_violin(aes(fill = "blue"), alpha = 0.5) +
       geom_boxplot(width = 0.1, color = "red") +
       labs(title = paste("Violin Plot de", columna),
            y = columna,
            x = "")
  
  # Muestra el violin plot
  print(p)
}

```


# Análisis de los datos.

## Selección de los grupos de datos que se quieren analizar/comparar.

Ahora queremos analizar la **variable ecg** en función de diferentes grupos de variables. Para llevar acabo esto hemos pensado en los siguientes grupos:

    1.- gender: además de comparar la variable ECG entre hombres y mujeres.
    
    2.- chestpain: en lugar de comparar la variable ECG solo entre pacientes con y sin dolor en el pecho.
    
    3.- restwma: esta variable indica si el paciente tiene o no anomalías en el movimiento de las paredes del corazón en reposo.
    
    4.- posSE: esta variable indica si el paciente tiene o no elevación del segmento ST en el electrocardiograma.
    
    5.- newMI, newPTCA, newCABG: estas variables indican si el paciente experimentó un infarto de miocardio o se sometió a una intervención coronaria.
    
    6.- death, any.event: estas variables indican si el paciente falleció o experimentó algún evento cardíaco adverso.
    
    7.- hxofHT, hxofDM, hxofMI, hxofPTCA, hxofCABG, hxofCig: estas variables indican si el paciente tiene antecedentes de hipertensión, diabetes, infarto de miocardio, intervención coronaria, cirugía de bypass o tabaquismo.




```{r}



```


## Comprobación de la normalidad y homogeneidad de la varianza.


```{r}



```


## Aplicación de pruebas estadísticas.


```{r}



```


# Conclusiones del estudio.




# Aplicación Shiny realizada para este estudio.














```{r}

# Convertir variable numérica en variable categórica:
stressEcho$hxofCig <- as.factor(stressEcho$hxofCig)

# Crear tabla de frecuencias con porcentajes:
hxofCig_table <- table(stressEcho$hxofCig)
hxofCig_table_percent <- prop.table(hxofCig_table) * 100

# Combinar resultados en un data frame:
hxofCig_table_df <- data.frame(hxofCig = names(hxofCig_table), count = as.vector(hxofCig_table), percent = as.vector(hxofCig_table_percent))

# Crear tabla con kable():
kable(hxofCig_table_df, col.names = c("hxofCig", "Count", "Percent"), linesep = "solid")

# Crear gráfico de barras:
ggplot(stressEcho, aes(x = hxofCig, fill = hxofCig)) +
  geom_bar() +
  labs(x = "hxofCig", y = "Count", fill = "hxofCig") +
  ggtitle("Distribution of hxofCig in Stress Echo Dataset")



```



```{r}

# Convertir variable numérica en variable categórica:
stressEcho$ecg <- as.factor(stressEcho$ecg)

# Crear tabla de frecuencias con porcentajes:
ecg_table <- table(stressEcho$ecg)
ecg_table_percent <- prop.table(ecg_table) * 100

# Combinar resultados en un data frame:
ecg_table_df <- data.frame(ecg = names(ecg_table), count = as.vector(ecg_table), percent = as.vector(ecg_table_percent))

# Crear tabla con kable():
kable(ecg_table_df, col.names = c("ecg", "Count", "Percent"), linesep = "solid")

# Crear gráfico de barras:
ggplot(stressEcho, aes(x = ecg, fill = ecg)) +
  geom_bar() +
  labs(x = "ecg", y = "Count", fill = "ecg") +
  ggtitle("Distribution of ecg in Stress Echo Dataset")

```



Trasformamos las variables númericas suceptibles de ser variables dicotómicas

```{r}


stressEcho$chestpain <- ifelse(stressEcho$chestpain == 0, 'Yes', 'Not')
stressEcho$chestpain <- as.factor(stressEcho$chestpain)

stressEcho$restwma <- ifelse(stressEcho$restwma == 0, 'Yes', 'Not')
stressEcho$restwma <- as.factor(stressEcho$restwma)

stressEcho$posSE <- ifelse(stressEcho$posSE == 0, 'Yes', 'Not')
stressEcho$posSE <- as.factor(stressEcho$posSE)

stressEcho$newMI <- ifelse(stressEcho$newMI == 0, 'Yes', 'Not')
stressEcho$newMI <- as.factor(stressEcho$newMI)

stressEcho$newPTCA <- ifelse(stressEcho$newPTCA == 0, 'Yes', 'Not')
stressEcho$newPTCA <- as.factor(stressEcho$newPTCA)

stressEcho$newCABG <- ifelse(stressEcho$newCABG == 0, 'Yes', 'Not')
stressEcho$newCABG <- as.factor(stressEcho$newCABG)

stressEcho$death <- ifelse(stressEcho$death == 0, 'Yes', 'Not')
stressEcho$death <- as.factor(stressEcho$death)

stressEcho$hxofHT <- ifelse(stressEcho$hxofHT == 0, 'Yes', 'Not')
stressEcho$hxofHT <- as.factor(stressEcho$hxofHT)

stressEcho$hxofDM <- ifelse(stressEcho$hxofDM == 0, 'Yes', 'Not')
stressEcho$hxofDM <- as.factor(stressEcho$hxofDM)

stressEcho$hxofMI <- ifelse(stressEcho$hxofMI == 0, 'Yes', 'Not')
stressEcho$hxofMI <- as.factor(stressEcho$hxofMI)

stressEcho$hxofPTCA <- ifelse(stressEcho$hxofPTCA == 0, 'Yes', 'Not')
stressEcho$hxofPTCA <- as.factor(stressEcho$hxofPTCA)

stressEcho$hxofCABG <- ifelse(stressEcho$hxofCABG == 0, 'Yes', 'Not')
stressEcho$hxofCABG <- as.factor(stressEcho$hxofCABG)

stressEcho$any.event <- ifelse(stressEcho$any.event == 0, 'Yes', 'Not')
stressEcho$any.event <- as.factor(stressEcho$any.event)
```


### 2.- Integración y selección.

Integración y selección de los datos de interés a analizar. Puede ser el resultado de adicionar diferentes datasets o una subselección útil de los datos originales, en base al objetivo que se quiera conseguir.



```{r}



```


### 3.- Limpieza de los datos.

#### 3.1.- ¿Los datos contienen ceros o elementos vacíos?.

Contamos el número de valores na por atributo:
```{r}


colSums(is.na(stressEcho))

```

```{r}


colSums(stressEcho=="")

```



Además, la variable “id” hace referencia a la identificación del paciente y esto no es interesante, por lo que la eliminaremos del dataframe

```{r}

stressEcho <- stressEcho[, -1]

```


#### 3.2.- Identifica y gestiona los valores extremos.


```{r}



```


### 4.- Análisis de los datos.

## 4.0. EDA

### 4.0.1 Matriz con gráficos de dispersión de las variables cuantitativas

### 4.0.2 Cálculo de los coeficientes de correlación entre variables
Estudiamos la correlación solo para variables númericas

```{r}
cor(stressEcho[sapply(stressEcho, is.numeric)])
```

A continuación, calculamos la correlación entre todas la variables, convirtiendo las variables categóricas en numericas.

```{r}
# Para variables numéricas y no numéricas. Será necesario transformar
# todas las variables en tipo numérico antes
stressEcho_numeric <- data.frame(lapply(stressEcho, function(x) as.numeric(x)))
cor(stressEcho_numeric)
```

#### 4.1.- Selección de los grupos de datos que se quieren analizar/comparar.





```{r}



```


#### 4.2.- Comprobación de la normalidad y homogeneidad de la varianza.


```{r}



```


#### 4.3.- Aplicación de pruebas estadísticas.


```{r}



```


### 5.- Representación gráfica de los resultados.


```{r}



```


### 6.- Resolución del problema.


```{r}



```










